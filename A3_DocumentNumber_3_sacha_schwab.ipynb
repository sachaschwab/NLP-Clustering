{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='darkblue'>MA5851 A3 Assessment Report Part Three </font>\n",
    "\n",
    "**<font color='darkblue'>Student: </font>Sacha Schwab**\n",
    "\n",
    "<font color='darkblue'>Location: </font>Zurich, Switzerland\n",
    "\n",
    "<font color='darkblue'>Date: </font>3 December 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:darkblue\">\n",
    "    1. The Task\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "    Following Part I of this assessment, the task in this section is to \n",
    "</p>\n",
    "\n",
    "\n",
    "<ol style=\"line-height: 1.5; font-size:12pt\">\n",
    "  <li>come up with, apply and evaluate, an NLP solution that provides extraction of events from the harvested articles data as well as grouping of the articles into same-event ones, and to </li>\n",
    "  <li>investigate the deployment of the NLP solution.</li>\n",
    "</ol>\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "    As shown below, event extraction is complex and usually involves several NLP, machine learning and/or deep learning techniques. \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:darkblue\">\n",
    "    2. Literature Review\n",
    "</h1>\n",
    "<style>\n",
    "  p {color:blue;}\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "    Numerous important events happen everyday and everywhere. The sources documenting events are numerous and diverse, with different narrative styles (Xiang and Wang, 2019). The literature is diverse when it comes to event extraction. Possible reasons for this diversity can be identified:\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "  <li>Coffee</li>\n",
    "  <li>Tea</li>\n",
    "  <li>Milk</li>\n",
    "</ul>\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "The basic task after collecting the article data through webcrawling is to group the articles into events. This task can be splitted into the sub-tasks:\n",
    "</p>\n",
    "    <ul style=\"line-height: 1.5; font-size:12pt\">\n",
    "        <li>Extracting the event(s) represented in the article by extracting the core arguments from the text (Li et al., 2021, p.1).</li>\n",
    "        <li>Clustering such that the articles with matching events are grouped together</li>\n",
    "    </ul>\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "The literature pertaining to event extraction (and subsequent clustering) is diverse insofar as it reflects a variety of\n",
    "</p>\n",
    "<ul style=\"line-height: 1.5; font-size:12pt\">\n",
    "  <li>definitions what an event is, i.e. the syntactical concepts applied vary, encompassing e.g. \"Actor-Action-Object-Time\" (e.g. in Xing et al., 2018), or a \"who, when, where, what, why, how\" syntax (see Xiang and Wang, 2019), or syntax schemes according to the event category under investigation (e.g. \"attacker-target-instrument-time-place\", see Li et al., 2021, p.2)</li>\n",
    "  <li>the range of events under investigation: A number of scientific papers cover a multitude of event categories, others, rather in the online tutorial space, limit to economic event articles, but are rather simplistic in the implementation of NLP and machine learning / deep learning tasks;</li>\n",
    "</ul>\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "In terms of the articles under investigation (market news on crypto assets), the challenges can be extended to the different structure of different article types, e.g.\n",
    "</p>\n",
    "<ul style=\"line-height: 1.5; font-size:12pt\">\n",
    "  <li>Titles often do not fully represent the event</li>\n",
    "      <li>Side events or multiple events mentioned (e.g. in daily summaries of events)</li>\n",
    "      <li>Different classes of articles even in the present sphere, such as market mover types, regulatory news, etc.\n",
    "      <li>„Simple“ Verb-argument patterns often not applicable, e.g. where multible entities are mentioned (Rusu et al., 2014)\n",
    "  </li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "The event extraction (sub-) task itself entails different NLP techniques, results of which can be further used, e.g. (see Xing et al., 2018)\n",
    "</p>\n",
    "<ul style=\"line-height: 1.5; font-size:12pt\">\n",
    "    <li>named entity extraction;</li>\n",
    "    <li>extract the relationships between the entities;</li>\n",
    "    <li>Identify the hierarchy (Actor or Object);</li>\n",
    "    <li>identify the verb being the ‘edge’ of the actor-object graph;;</li>\n",
    "    <li>extract the relevant time;</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "The literature appears to apply event extraction such that each article is expressed in a schema-conform way so that not only the event class is identified, but also the article content is mapped according to the schema applicable to the class. <br><br>\n",
    "Li et al. (2021) investigated the approaches applied by the literature, and divided them into 3 groups, which are: (1) pattern-matching, (2) machine learning, and (3) deep learning. They also state that the recent work focuses on combinations of deep learning techniques. This in order to overcome the challenges of the first two groups, which are, among other, the need of using large-scale corpora, and challenges in learning in-depth features.<br><br>\n",
    "Goya et al. (2018, p. 24) find that a combination of named entities and keywords improves the clustering quality. In particular, named entity recognition has shown a remarkable improvement for clustering.<br><br>\n",
    "Capdevila et al. (2016, p. 1 f) and further resources describe DBSCAN constitute a well-known approach to event detection due its noise resilience capability.<br><br>\n",
    "Cao et al., 2012 conclude from their research that a weighted combination of named entities and keywords are significant to clustering quality.<br><br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:darkblue\">\n",
    "    3. Conclusions from Literature Review\n",
    "</h1>\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "The literature covers a wide range of techniques applicable for event extraction. In particular, deep learning methods appear to be on the verge, with their advantages being e.g. more efficient and effective categorisation and structuring of event information that fit pre-defined schemas, or schemas that are built as a result of (highly complex) extraction processes.\n",
    "Content similarity detection appear attractive for the task at hand. However, events can develop on a mid to long term scale (e.g. a month ago, company X was invetigated for embezzlement, today it is charged in the same case). Content similarity detection methods may be less successful than the event extraction methods proposed by the literature, however not less interesting. They may serve for future investigations.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:darkblue\">\n",
    "    4. Approach\n",
    "</h1>\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "The aim of this assessment is not to apply highly granular and precise classification and information extraction, but to group articles reflecting the same event. This implies that the neither the category nor schmema-applicable data needs to be identified. A further challenge is the available time for this assessment, which excludes extensive investigations into deep learning architectures.<br><br>\n",
    "Besides event extraction, content similarity detection is another field of research and application, with diferent methods detected so far, such as fingerprint algorithms, string matchi, bag of words, stylometry (see Wikipedia on Content similarity detection). Applications that use these detection methods are search engines (where the presented result considers multiple similar documents), plagiarism or copyright infringement.\n",
    "Based on the literature review general considerations regarding this assessment and, since according to the assessment outline precisely two NLP tasks must be considered, I will select the following architecture, with variations:\n",
    "</p>\n",
    "\n",
    "<ul style=\"line-height: 1.5; font-size:12pt\">\n",
    "  <li>Identify the named entities and their relations;\n",
    "  <li>Identify keywords using word embedding;\n",
    "  <li>Apply clustering technique;\n",
    "  <li>Measure the performance of the model variations.\n",
    "  </li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "The algorithms applied are:\n",
    "</p>\n",
    "\n",
    "<ul style=\"line-height: 1.5; font-size:12pt\">\n",
    "  <li>Named entity extraction and relations: NLTK\n",
    "  <li>For embeddings: TF-IDF (using the corpus obtained through webcrawling) and BERT (pre-trained model)\n",
    "  <li>For clustering: DBSCAN since the number of clusters is not known, and due to indications in the literature.\n",
    "  </li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "More in detail, the approach for generation of an initial list of articles per events entails the following workflow:\n",
    "</p>\n",
    "\n",
    "<ol style=\"line-height: 1.5; font-size:12pt\">\n",
    "  <li>Crawl as many articles as possible to build an appropriately sized corpus\n",
    "  <li>Preprocess the text data\n",
    "  <li>Apply embeddings (which entail tokenization)\n",
    "  <li>Select key words (50 most important words)\n",
    "  <li>Find named entities and relations in the texts\n",
    "  <li>With the features being the named entities (indices from dictionary) and key word embedding vectors, apply DBSCAN. Vary by adding the relationship as feature.\n",
    "</ol>\n",
    "\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "The output of the model is a vector of the cluster IDs mapped to the articles. The finetuned model will be used by the development team as follows (pipeline including webcrawling):\n",
    "</p>\n",
    "\n",
    "<ol style=\"line-height: 1.5; font-size:12pt\">\n",
    "  <li>Crawl new articles of the day\n",
    "  <li>Preprocess texts\n",
    "  <li>Find embeddings\n",
    "  <li>Find named entities\n",
    "  <li>Using the cluster model, allocate new articles to existing articles (using a sliding window, e.g. current day - 3 months since assuming that events do not 'not occur' for 3 months, or only in rare cases. Thus, it is assured that articles connected with the same event are recognised)\n",
    "  </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:darkblue\">\n",
    "    TODO\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since TF-IDF computes the importance of a term in a document (taking all other documents in the corpus into account), it is appropriate for finding keywords (see e.g. Ellis, 2019)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "Data preprocessing includes lower-casing, erasure of one-character words and symbols as well lemmatization. The latter is applied knowing that it is slower, however appears to make more sense since it better reflects natural speech than stemming (Jabeen, 2018).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:darkblue\">\n",
    "    4. NLP Tasks\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:darkblue\">\n",
    "    a) Embedding\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:darkblue\">\n",
    "    a) Keyword extraction\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"line-height: 1.5; font-size:12pt; color:darkblue\">\n",
    "TF-IDF\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since TF-IDF computes the importance of a term in a document (taking all other documents in the corpus into account), it is appropriate for finding keywords (see e.g. Ellis, 2019)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:darkblue\">\n",
    "    Named Entities\n",
    "</h2>\n",
    "\n",
    "Spacy still appears to have flaws as shown below (cryptocurrencies are mentiond as parts of various categories, however it is generally very powerful. I will add a layer to allocate the cryptocurrencies as entities, since they are a central part of this assessment. The data is taken from https://coinmarketcap.com/all/views/all/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:darkblue\">\n",
    "    Sentiment Analysis\n",
    "</h2>\n",
    "\n",
    "The compound score is the sum of positive, negative and neutral scores, adn these are normalized between -1 (highly  negative) and +1 (highly positive). To "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:darkblue\">\n",
    "    Clustering with DBSCAN\n",
    "</h2>\n",
    "\n",
    "From Wikipedia: \"The silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation). The silhouette ranges from −1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "- It is unlikely that no articles would have no 'companion', i.e. that there is no noise\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
