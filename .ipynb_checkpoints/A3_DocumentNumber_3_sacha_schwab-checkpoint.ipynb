{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='darkblue'>MA5851 A3 Assessment Report Part Three (NLP Tasks)</font>\n",
    "\n",
    "**<font color='darkblue'>Student: </font>Sacha Schwab**\n",
    "\n",
    "<font color='darkblue'>Location: </font>Zurich, Switzerland\n",
    "\n",
    "<font color='darkblue'>Date: </font>3 December 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:darkblue\">\n",
    "    1. The Task\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "    Following Part I of this assessment, the task in this section is to \n",
    "</p>\n",
    "\n",
    "\n",
    "<ol style=\"line-height: 1.5; font-size:12pt\">\n",
    "  <li>come up with, apply and evaluate, an NLP solution that provides extraction of events from the harvested articles data as well as grouping of the articles into same-event ones, and to </li>\n",
    "  <li>investigate the deployment of the NLP solution.</li>\n",
    "  <li>apply machine learning to 'round up' the solution.</li>\n",
    "</ol>\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "    As shown below, event extraction is complex and usually involves several NLP, machine learning and/or deep learning techniques. \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:darkblue\">\n",
    "    Preliminary thoughts\n",
    "</h2>\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "    <p style=\"line-height: 1.5; font-size:12pt\">\n",
    "The basic task after collecting the article data through webcrawling is to group the articles into events. This task can be splitted into the sub-tasks:\n",
    "</p>\n",
    "    <ul style=\"line-height: 1.5; font-size:12pt\">\n",
    "        <li>Extracting the event(s) represented in the article by extracting the core arguments from the text (Li et al., 2021, p.1).</li>\n",
    "        <li>Clustering such that the articles with matching events are grouped together</li>\n",
    "    </ul>\n",
    "</p>\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "In terms of the news articles under investigation (market news on crypto assets), the challenges can be extended to the different structure of different article types, e.g.\n",
    "</p>\n",
    "<ul style=\"line-height: 1.5; font-size:12pt\">\n",
    "  <li>Titles often do not fully represent the event</li>\n",
    "      <li>Side events or multiple events mentioned (e.g. in daily summaries of events)</li>\n",
    "      <li>Different classes of articles even in the present sphere, such as market mover types, regulatory news, etc.\n",
    "      <li>„Simple“ Verb-argument patterns often not applicable, e.g. where multible entities are mentioned (Rusu et al., 2014)\n",
    "  </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:darkblue\">\n",
    "    2. Literature Review\n",
    "</h1>\n",
    "<style>\n",
    "  p {color:blue;}\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "    Numerous important events happen everyday and everywhere. The sources documenting events are numerous and diverse, with different narrative styles (Xiang and Wang, 2019). The literature is diverse when it comes to event extraction. Possible reasons for this diversity can be identified:\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "  <li>Coffee</li>\n",
    "  <li>Tea</li>\n",
    "  <li>Milk</li>\n",
    "</ul>\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "The literature pertaining to event clustering is diverse insofar as it reflects a variety of\n",
    "</p>\n",
    "<ul style=\"line-height: 1.5; font-size:12pt\">\n",
    "  <li>definitions what an event is, i.e. the syntactical concepts applied vary, encompassing e.g. \"Actor-Action-Object-Time\" (e.g. in Xing et al., 2018), or a \"who, when, where, what, why, how\" syntax (see Xiang and Wang, 2019), or syntax schemes according to the event category under investigation (e.g. \"attacker-target-instrument-time-place\", see Li et al., 2021, p.2)</li>\n",
    "  <li>the range of events under investigation: A number of scientific papers mainly covers the issue that text can be presented such that a multitude of event categories can be derived, others, rather in the online tutorial space, limit to economic event articles, but are rather simplistic in the implementation of NLP and machine learning / deep learning tasks;</li>\n",
    "    <li>considering the need to cateorise events, the literature has developed th 'event extraction' study field with a diverse range of approaches (see below).;</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "As to the event extraction (sub-) task itself the literture investigates and proposes different NLP techniques, results of which can be further used (see Xing et al., 2018):\n",
    "</p>\n",
    "<ul style=\"line-height: 1.5; font-size:12pt\">\n",
    "    <li>named entity extraction;</li>\n",
    "    <li>extract the relationships between the entities;</li>\n",
    "    <li>Identify the hierarchy (Actor or Object);</li>\n",
    "    <li>identify the verb being the ‘edge’ of the actor-object graph;;</li>\n",
    "    <li>extract the relevant time;</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "A considerable part of the literature uses event extraction approaches such that each article is expressed in a schema-conform way so that not only the event class is identified, but also the article content is mapped according to the schema applicable to the class. <br><br>\n",
    "Li et al. (2021) investigated the approaches applied by the literature, and divided them into 3 groups, which are: (1) pattern-matching, (2) machine learning, and (3) deep learning. They also state that the recent work focuses on combinations of deep learning techniques. This in order to overcome the challenges of the first two groups, which are, among other, the need of using large-scale corpora, and challenges in learning in-depth features.<br><br>\n",
    "As to clustering, Goya et al. (2018, p. 24) find that a combination of named entities and keywords improves the clustering quality. In particular, named entity recognition has shown a remarkable improvement for clustering.<br><br>\n",
    "Capdevila et al. (2016, p. 1 f) and further resources describe DBSCAN constitute a well-known approach to event detection due its noise resilience capability.<br><br>\n",
    "Cao et al., 2012 conclude from their research that a weighted combination of named entities and keywords are significant to clustering quality.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:darkblue\">\n",
    "    3. Conclusions from Literature Review\n",
    "</h1>\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "The literature covers a wide range of techniques applicable for event extraction. In particular, deep learning methods appear to be on the verge, with the obvious benefit of being able to treat vectors as sequence, and other advantages being e.g. more efficient and effective categorisation and structuring of event information that fit pre-defined schemas, or schemas that are built as a result of (highly complex) extraction processes.\n",
    "Content similarity detection appear attractive for the task at hand. However, events can develop on a mid to long term scale (e.g. a month ago, company X was invetigated for embezzlement, today it is charged in the same case). Content similarity detection methods may be less successful than the event extraction methods proposed by the literature, however not less interesting. Content similarity will serve for my future investigations into the problem set.<br><br>\n",
    "Caveat: Besides event extraction, content similarity detection is another field of research and application, with diferent methods detected so far, such as fingerprint algorithms, string match, bag of words, stylometry (see Wikipedia on Content similarity detection). Applications that use these detection methods are search engines (where the presented result considers multiple similar documents), plagiarism or copyright infringement. Since news articles describing same events may have a completely different structure and size content similarity detection is not considered in this project. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:darkblue\">\n",
    "    4. Approach\n",
    "</h1>\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "The aim of this assessment is not to apply highly granular and precise classification and information extraction, but to group articles reflecting the same event. Preliminary categorsation based on schmemata would have been preferrable. However, since one main challenge in this project is the limited time available, which excludes extensive investigations into deep learning architectures.<br><br>\n",
    "Based on the literature review general considerations regarding this assessment and, since according to the assessment outline precisely two NLP tasks must be considered, I will select the following architecture, with variations:\n",
    "</p>\n",
    "\n",
    "<ul style=\"line-height: 1.5; font-size:12pt\">\n",
    "  <li>Identify the named entities and their relations;\n",
    "  <li>Identify keywords using word embedding;\n",
    "  <li>Apply clustering technique;\n",
    "  <li>Measure the performance of the model variations.\n",
    "  </li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "The algorithms applied are:\n",
    "</p>\n",
    "\n",
    "<ul style=\"line-height: 1.5; font-size:12pt\">\n",
    "  <li>Named entity extraction and relations: NLTK\n",
    "  <li>For embeddings: TF-IDF (using the corpus obtained through webcrawling)\n",
    "  <li>For clustering: DBSCAN since the number of clusters is not known, and due to indications in the literature.\n",
    "  </li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "More in detail, the approach for generation of an initial list of articles per events entails the following workflow:\n",
    "</p>\n",
    "\n",
    "<ol style=\"line-height: 1.5; font-size:12pt\">\n",
    "  <li>Crawl as many articles as possible to build an appropriately sized corpus\n",
    "  <li>Preprocess the text data\n",
    "  <li>Apply embeddings (which entail tokenization)\n",
    "  <li>Select key words (50 most important words)\n",
    "  <li>Find named entities and relations in the texts\n",
    "  <li>With the features being the named entities (indices from dictionary) and key word embedding vectors, apply DBSCAN. Vary by adding the relationship as feature.\n",
    "</ol>\n",
    "\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "The output of the model is a vector of the cluster IDs mapped to the articles. The finetuned model will be used by the development team as follows (pipeline including webcrawling):\n",
    "</p>\n",
    "\n",
    "<ol style=\"line-height: 1.5; font-size:12pt\">\n",
    "  <li>Run new articles crawling daily\n",
    "  <li>Run refresh of the model daily (this includes preprocessing etc.)\n",
    "  <li>Reflecting the use case: Utilising the cluster model, allocate new articles to existing articles (using a sliding window, e.g. current day - 3 months since assuming that events do not 'not occur' for 3 months, or only in rare cases. Thus, it is assured that articles connected with the same event are recognised)\n",
    "  </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:darkblue\">\n",
    "    5. Data Wrangling\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "    In this part the harvested data generated by the web crawler is preprocessed and tokenised for further use for NLP tasks.<br>\n",
    "    Data preprecessing follows a rather standard approach as per literature indications, learning materials in MA5851, and online tutorials. It includes lower-casing, erasure of one-character words and symbols as well lemmatization. The latter is applied knowing that it is slower, however appears to make more sense since it better reflects natural speech than stemming (Jabeen, 2018).\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary and visuallisation of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"line-height: 1.5; font-size:12pt\">Reference is made to section (k) of the submitted report for part 2 of this assessment.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:darkblue\">\n",
    "    6. NLP Tasks\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding / Vectorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "   One of the aims of the NLP part, as shown above, is keyword extraction. This is achieved by evaluating the importance weights of the words in a document, then selecting the words with the top x weights.<br>\n",
    "    For embedding, various techniques are available, including TF-IDF, BERT, Word2Vec, Bag of Words. It appears from literature review that BERT is on the verge of becoming the standard approach for this task. It has been pre-investigated for this project, however, for efficiency reasons TF-IDF was selected.<br>\n",
    "    Since TF-IDF computes the importance of a term in a document (taking all other documents in the corpus into account), it is appropriate for finding keywords (see e.g. Ellis, 2019).<br>\n",
    "    The TfidfVectorizer from NLTK package was employed for the purpose of producing TF-IDF vectors.<br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "   This subtask follows a rather logical approach: For each document every word in the tokenised text is looked up in the TF-IDDF matrix, its weight collected and put into a dataframe for sorting, evaluating the weight value of the (top) x'st word, and dropping all other words. The two arrays (top x words and their weights) are returned for their use in the clustering task below.<br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "   For this rather complex task a number of pre-trained models can be employed. Due to lack of available time for this project, a rather quick search retrieved the Spacy framework. In first tests the named entity recognition section returned a surprisingly accurate representation of entities, places, dates etc.<br>\n",
    "Spacy still appears to have flaws as shown below (cryptocurrencies are mentiond as parts of various categories, however it appears generally very powerful. A layer to allocate the cryptocurrencies had to be skipped due to lack of time, however should be added in a next release.<br>\n",
    "    Then, the same \"select top x\" approach as for keyword extraction above was selected.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "   For this NLP task a rather simplistic approach was selected for efficiency reasons, i.e. application of the VADER sentiment analysis (SentimentIntensityAnalyzer from NLTK), which was run for every document.<br>\n",
    "   The resulting compound score is the sum of positive, negative and neutral scores, adn these are normalized between -1 (highly  negative) and +1 (highly positive).<br>\n",
    "    An approach would be to provide the category (positive, negative, neutral), however for the clustering, and also for more flexible interpretation of the results I left the compound score values as presented by VADER.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Task Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output from keyword extraction\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\"><br>The output below indicates that there is some more work to do here, since (a) non-english stopwords appear (\"el\", \"de\" etc.) and (b) frequent unwanted concatenations take place previous to the keyword extraction.</p>\n",
    "\n",
    "<img src=\"assets/keyword_freq.png\" alt=\"HDBSCAN output\" width=\"1000\" align=\"center\"></img>\n",
    "<p style=\"font-size:10pt; text-align:center\">Figure: Frequency distribution of extracted entities</p><br>\n",
    "\n",
    "<img src=\"assets/keyword_weight_hist.png\" alt=\"HDBSCAN output\" width=\"500\" align=\"center\"></img>\n",
    "<p style=\"font-size:10pt; text-align:center\">Figure: Frequency distribution of extracted entities</p><br>\n",
    "\n",
    "#### Output from entity extraction\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\"><br>Also here the output could be more meaningful. The distribution of weights indicates that the entities' importance is generally rather inferior, i.e. the entities, as to be observed above, are not represented among the keywords as it might be expected. </p>\n",
    "\n",
    "<img src=\"assets/entities_distribution.png\" alt=\"HDBSCAN output\" width=\"1000\" align=\"center\"></img>\n",
    "<p style=\"font-size:10pt; text-align:center\">Figure: Frequency distribution of extracted entities</p><br>\n",
    "<img src=\"assets/entities_weights.png\" alt=\"HDBSCAN output\" width=\"800\"/></img>\n",
    "\n",
    "\n",
    "#### Output from sentimeent analysis\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "    The sentiment analysis provided scores, as shown in below figure, that are unequally distributed: The scores for the titles have a very strong tendency to be 0, the texts however towards 1, i.e. the sentiment representations of titles and body texts do not match at all. Different reasons could apply, e.g. the Yahoo article choice bein 'uncontroversial', i.e. a tendency of the article selection by Yahoo to take on rather positive reports which in many cases have a 'neutral' title. \n",
    "</p>\n",
    "<img src=\"assets/sent_distribution.png\" alt=\"HDBSCAN output\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:darkblue\">\n",
    "    7. Machine Learning\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "    Following indications in the literature (see above section 2) DBSCAN was investigated in a preliminary stage, then complemented with a comparison with HDBSCAN, which adds hierarchical clustering.<br>\n",
    "For evaluation and preliminary parameter tuninig the silhouette score was selected. From Wikipedia: \"The silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation). The silhouette ranges from −1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.\" It appears as an appropriate measure for the task at hand since it should provide an appropriate basis for parameter tuning and interpretation of the model.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "    DBSCAN ought to be run with variations of the eps and the min_samples parameters. Preliminary thought was to start with a low eps value since considerable noise is expected (due to many events being presented in news articles over the short time period under investigation).<br>\n",
    "For this task, and following preliminary runs, the number of top keywords and extracted entities was set to 10.  Together with the two sentiment scores for news article titles and body texts a total of 22 rows of normmalised values served as input.<br>\n",
    "The result was that DBSCAN would not present meaningful results: The algorithm would recognise either a cluster label for every article, or find only noise and one label (0). <br></p>\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">Conclusion: DBSCAN cannot be employed for the task at hand. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "    Parameter variations for HDBSCAN provide results that are more in the space of expectations (see above considerations), i.e. a rather high level of noise and a rather small number of actual clusters as shown in the visualisation below.<br>\n",
    "Based on preliminary checks, variations were applied to parameters leaf_size (20 and 80) and min_samples (none and 1). Since we can regard a single-article cluster as noise, the minimum cluster size was set to 2. </p><br>\n",
    "<img src=\"assets/hdbscan_output.png\" alt=\"HDBSCAN output\" width=\"1000\"/>\n",
    "<p style=\"font-size:10pt; text-align:center\">Figure: Resulting cluster distribution from HDBSCAN</p>\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">Also, the silhouette scores are not in a satisfactory range:</p>\n",
    "<img src=\"assets/silh_hdbscan.png\" alt=\"HDBSCAN Silhouette scores\" width=\"700\"/>\n",
    "<p style=\"font-size:10pt; text-align:center\">Figure: Silhouette scores obtained</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions (\"Show case\")\n",
    "\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">As a result of all this, the user will want to know whether there are any matches of a sample news article, and what the articles are that the model includes in the cluster. For the purpose of allocating new points in the model, HDBSCAN provides the function 'approximate_predict'.<br>\n",
    "The following shows the reesult for a sample taken from the above used data themselves. The result is not very promising, however a start for further iterations.</p>\n",
    "\n",
    "<img src=\"assets/cluster_display_.png\" alt=\"HDBSCAN Silhouette scores\" width=\"700\"/>\n",
    "<p style=\"font-size:10pt; text-align:center\">Figure: HDBSCAN cluster match result</p>\n",
    "\n",
    "\n",
    "### Conclusion:\n",
    "<p style=\"line-height: 1.5; font-size:12pt\">\n",
    "    The distribution of clusters varies quite significantly. The reasons for this may lie in the fact that the keyword and named entities features have different importance (weights) and have to be understood as sequential input. The preliminary results here indicate that DBSCAN/HDBSCAN clustering should rather be employe on information to be extracted from the texts. Further alternatives to be investigated are the application of a kernel that 'summarizes' the vectors.<br></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
